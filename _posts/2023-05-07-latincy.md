---
title: "LatinCy: Synthetic Trained Pipelines for Latin NLP"
layout: paper
date: 2023-05-07 00:00
tag: paper
image:
headerImage: false
projects: false
hidden: true # don't count this post in blog pagination
description: "Preprint on arXiv"
jemoji: '<img class="emoji" title=":paper:" alt=":paper:" src="../assets/images/paper-icon.png" height="20" width="20" align="absmiddle">'
author: patrickburns
externalLink: false
---

# LatinCy: Synthetic Trained Pipelines for Latin NLP
*Preprint available at  [arXiv:2305.04365 \[cs.CL\]](https://arxiv.org/abs/2305.04365)*

{:.paper-section-heading}
## Abstract
This paper introduces LatinCy, a set of trained general purpose Latin-language "core" pipelines for use with the spaCy natural language processing framework. The models are trained on a large amount of available Latin data, including all five of the Latin Universal Dependency treebanks, which have been preprocessed to be compatible with each other. The result is a set of general models for Latin with good performance on a number of natural language processing tasks (e.g. the top-performing model yields POS tagging, 97.41% accuracy; lemmatization, 94.66% accuracy; morphological tagging 92.76% accuracy). The paper describes the model training, including its training data and parameterization, and presents the advantages to Latin-language researchers of having a spaCy model available for NLP work. 

{:.paper-section-heading}
## Citation
Burns, P.J. 2023. “LatinCy: Synthetic Trained Pipelines for Latin NLP.” arXiv:2305.04365 [cs.CL]. http://arxiv.org/abs/2305.04365.  
